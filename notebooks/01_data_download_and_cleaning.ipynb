{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43e45d21-23a7-4d7d-ae0c-aeb1a6abe636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a49d285b-4e94-439d-9c4e-d26dd0ed562f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>24.288576</td>\n",
       "      <td>24.757330</td>\n",
       "      <td>23.848702</td>\n",
       "      <td>24.746222</td>\n",
       "      <td>212818400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>23.604334</td>\n",
       "      <td>24.137514</td>\n",
       "      <td>23.417722</td>\n",
       "      <td>24.057537</td>\n",
       "      <td>257142000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>23.606552</td>\n",
       "      <td>23.866477</td>\n",
       "      <td>23.244433</td>\n",
       "      <td>23.668756</td>\n",
       "      <td>263188400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>23.937565</td>\n",
       "      <td>24.037535</td>\n",
       "      <td>23.704298</td>\n",
       "      <td>23.815377</td>\n",
       "      <td>160423600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>24.857311</td>\n",
       "      <td>24.915073</td>\n",
       "      <td>24.148625</td>\n",
       "      <td>24.266371</td>\n",
       "      <td>237458000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price           Close       High        Low       Open     Volume\n",
       "Ticker           AAPL       AAPL       AAPL       AAPL       AAPL\n",
       "Date                                                             \n",
       "2015-01-02  24.288576  24.757330  23.848702  24.746222  212818400\n",
       "2015-01-05  23.604334  24.137514  23.417722  24.057537  257142000\n",
       "2015-01-06  23.606552  23.866477  23.244433  23.668756  263188400\n",
       "2015-01-07  23.937565  24.037535  23.704298  23.815377  160423600\n",
       "2015-01-08  24.857311  24.915073  24.148625  24.266371  237458000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = yf.download(\"AAPL\", start = \"2015-01-01\", end = \"2020-01-01\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2509b75b-9aa4-45a2-9f80-429c51e232cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(tickers, start='2015-01-01', end=None, save_path=None):\n",
    "    \"\"\"\n",
    "    Downloads historical market data for given tickers using yfinance and saves each as a CSV.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    tickers : list of str\n",
    "        A list of stock ticker symbols to download (e.g., ['AAPL', 'MSFT']).\n",
    "    start : str, optional\n",
    "        Start date for the data in 'YYYY-MM-DD' format. Default is '2010-01-01'.\n",
    "    end : str or None, optional\n",
    "        End date for the data in 'YYYY-MM-DD' format. Default is None (uses today's date).\n",
    "    save_path : str, optional\n",
    "        Directory where raw CSV files will be saved. Default is 'data/raw'.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary mapping each ticker to its corresponding raw DataFrame.\n",
    "        Tickers that fail to download are skipped with an error message.\n",
    "    \"\"\"\n",
    "    if end is None:\n",
    "        end = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "    data = {}\n",
    "    for ticker in tickers:\n",
    "        print(f\"Downloading {ticker}...\")\n",
    "        try:\n",
    "            df = yf.download(ticker, start=start, end=end)\n",
    "            if df.empty:\n",
    "                print(f\"Warning: No data found for '{ticker}'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            df['Ticker'] = ticker\n",
    "            data[ticker] = df\n",
    "\n",
    "            if save_path:\n",
    "                os.makedirs(save_path, exist_ok=True)\n",
    "                df.to_csv(f\"{save_path}/{ticker}_raw.csv\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading '{ticker}': {e}\")\n",
    "            continue\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5afbbf8e-c575-4284-82ff-063b1493625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df, ticker=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Cleans a raw stock price DataFrame by handling missing values, duplicates, and invalid rows.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Raw stock data to be cleaned. Must contain columns: ['Open', 'High', 'Low', 'Close', 'Volume'].\n",
    "    ticker : str, optional\n",
    "        Ticker symbol used for logging purposes. Default is None.\n",
    "    verbose : bool, optional\n",
    "        Whether to print the cleaning logs. Default is True.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    tuple\n",
    "        (cleaned_df, logs)\n",
    "        cleaned_df : pandas.DataFrame\n",
    "            The cleaned DataFrame.\n",
    "        logs : list of str\n",
    "            Log messages describing what cleaning steps were applied.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(f\"Expected a pandas DataFrame, but got {type(df).__name__}\")\n",
    "\n",
    "    # Check for required columns\n",
    "    required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    missing = [col for col in required_columns if col not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    logs = []\n",
    "    ticker_info = f\"[{ticker}]\" if ticker else \"\"\n",
    "\n",
    "    initial_rows = df.shape[0]\n",
    "    logs.append(f\"{ticker_info} Initial rows: {initial_rows}\")\n",
    "\n",
    "    # Convert index to datetime format\n",
    "    try:\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "    except Exception as e:\n",
    "        raise ValueError(\"Index could not be converted to datetime format.\") from e\n",
    "\n",
    "    # Remove duplicate rows\n",
    "    df = df.sort_index()\n",
    "    df = df[~df.index.duplicated(keep='first')]\n",
    "    logs.append(f\"{ticker_info} Removed duplicate index entries.\")\n",
    "\n",
    "    # Remove missing values\n",
    "    before = df.shape[0]\n",
    "    df = df.dropna(subset=required_columns)\n",
    "    logs.append(f\"{ticker_info} Dropped {before - df.shape[0]} rows with NaNs.\")\n",
    "\n",
    "    # Remove nonsense entries\n",
    "    before = df.shape[0]\n",
    "    df = df[(df['Open'] > 0) & (df['High'] > 0) & (df['Low'] > 0) & (df['Close'] > 0) & (df['Volume'] >= 0)]\n",
    "    logs.append(f\"{ticker_info} Dropped {before - df.shape[0]} rows with invalid values.\")\n",
    "\n",
    "    # Final cleanup of NA's\n",
    "    df = df.ffill().bfill()\n",
    "    logs.append(f\"{ticker_info} Final rows: {df.shape[0]}\")\n",
    "\n",
    "    if verbose:\n",
    "        for line in logs:\n",
    "            print(line)\n",
    "\n",
    "    return df, logs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58aac108-41c7-463f-a96d-f27c0719921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_clean_data(raw_data_dict):\n",
    "    \"\"\"\n",
    "    Applies the clean_data function to each DataFrame in a dictionary of raw data.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    raw_data_dict : dict\n",
    "        Dictionary where keys are ticker symbols and values are raw DataFrames.\n",
    "    verbose : bool, optional\n",
    "        Whether to print cleaning logs for each ticker. Default is True.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    tuple\n",
    "        (cleaned_data_dict, all_logs)\n",
    "        cleaned_data_dict : dict\n",
    "            Dictionary with cleaned DataFrames.\n",
    "        all_logs : dict\n",
    "            Dictionary mapping ticker symbols to their corresponding cleaning logs.\n",
    "    \"\"\"\n",
    "    cleaned_data = {}\n",
    "    logs = {}\n",
    "\n",
    "    for ticker, df in raw_data_dict.items():\n",
    "        cleaned_df, log = clean_data(df, ticker)\n",
    "        cleaned_data[ticker] = cleaned_df\n",
    "        logs[ticker] = log\n",
    "\n",
    "    return cleaned_data, logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f309e30-46fd-4f3a-ba5b-d6eff643193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    '''\n",
    "    Loads a CSV file as a DataFrame with a datetime index.\n",
    "\n",
    "    '''\n",
    "\n",
    "    df = pd.read.csv(file_path, index_col=0, parse_dates=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a35f03e-11cc-4e64-92bd-2aed5cf8e7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_clean_data(df, ticker, save_path=\"data/clean\", log_path=None):\n",
    "    \"\"\"\n",
    "    Saves a cleaned DataFrame to a CSV file with a standardized filename.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The cleaned DataFrame to be saved.\n",
    "    ticker : str\n",
    "        The stock ticker symbol (used in the filename).\n",
    "    save_path : str, optional\n",
    "        Directory where the cleaned CSV will be saved. Default is 'data/clean'.\n",
    "    log_path : str or None, optional\n",
    "        If provided, a log entry will be written to this file upon successful save.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    file_name = f\"{ticker}_clean.csv\"\n",
    "    file_path = os.path.join(save_path, file_name)\n",
    "    \n",
    "    df.to_csv(file_path)\n",
    "    \n",
    "    print(f\"[Saved] Cleaned data saved to: {file_path}\")\n",
    "    \n",
    "    if log_path:\n",
    "        with open(log_path, 'a') as f:\n",
    "            f.write(f\"{pd.Timestamp.now()}: Saved cleaned data for {ticker} to {file_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "566c5f33-68fe-4d15-ab13-e5456b76cc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_pipeline_step(log_path, message):\n",
    "    \"\"\"\n",
    "    Appends a timestamped message to a log file.\n",
    "\n",
    "    This function is useful for recording the steps of a data pipeline,\n",
    "    such as downloading, cleaning, or saving data, to help with debugging,\n",
    "    traceability, and auditing.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    log_path : str\n",
    "        The file path to the log file where the message will be saved.\n",
    "        If the file does not exist, it will be created.\n",
    "    message : str\n",
    "        The message to log. It will be prefixed with the current timestamp.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    with open(log_path, 'a') as f:\n",
    "        f.write(f\"{pd.Timestamp.now()}: {message}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d88e64f-c736-4778-8198-5c5f18ea678a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (StatArb)",
   "language": "python",
   "name": "stat-arb-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
