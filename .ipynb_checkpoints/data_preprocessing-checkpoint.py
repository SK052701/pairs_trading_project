{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a90a269a-56d0-4efc-b5e7-5dee797227b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea74fd7d-7975-478c-8a7b-8e8869197341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Download raw data\n",
    "def download_data(tickers, start='2015-01-01', end=None, save_path=None):\n",
    "    \"\"\"\n",
    "    Downloads historical market data for given tickers using yfinance and saves each as a CSV.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    tickers : list of str\n",
    "        A list of stock ticker symbols to download (e.g., ['AAPL', 'MSFT']).\n",
    "    start : str, optional\n",
    "        Start date for the data in 'YYYY-MM-DD' format. Default is '2010-01-01'.\n",
    "    end : str or None, optional\n",
    "        End date for the data in 'YYYY-MM-DD' format. Default is None (uses today's date).\n",
    "    save_path : str, optional\n",
    "        Directory where raw CSV files will be saved. Default is 'data/raw'.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary mapping each ticker to its corresponding raw DataFrame.\n",
    "        Tickers that fail to download are skipped with an error message.\n",
    "    \"\"\"\n",
    "    if end is None:\n",
    "        end = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "    data = {}\n",
    "    for ticker in tickers:\n",
    "        print(f\"Downloading {ticker}...\")\n",
    "        try:\n",
    "            df = yf.download(ticker, start=start, end=end)\n",
    "            if df.empty:\n",
    "                print(f\"Warning: No data found for '{ticker}'. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            df['Ticker'] = ticker\n",
    "            data[ticker] = df\n",
    "\n",
    "            if save_path:\n",
    "                os.makedirs(save_path, exist_ok=True)\n",
    "                df.to_csv(f\"{save_path}/{ticker}_raw.csv\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading '{ticker}': {e}\")\n",
    "            continue\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15f23386-8d45-4a11-84fa-d7cad57cd8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Clean a single DataFrame\n",
    "def clean_data(df, ticker=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Cleans a raw stock price DataFrame by handling missing values, duplicates, and invalid rows.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Raw stock data to be cleaned. Must contain columns: ['Open', 'High', 'Low', 'Close', 'Volume'].\n",
    "    ticker : str, optional\n",
    "        Ticker symbol used for logging purposes. Default is None.\n",
    "    verbose : bool, optional\n",
    "        Whether to print the cleaning logs. Default is True.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    tuple\n",
    "        (cleaned_df, logs)\n",
    "        cleaned_df : pandas.DataFrame\n",
    "            The cleaned DataFrame.\n",
    "        logs : list of str\n",
    "            Log messages describing what cleaning steps were applied.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(f\"Expected a pandas DataFrame, but got {type(df).__name__}\")\n",
    "\n",
    "    # Check for required columns\n",
    "    required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "    missing = [col for col in required_columns if col not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "    logs = []\n",
    "    ticker_info = f\"[{ticker}]\" if ticker else \"\"\n",
    "\n",
    "    initial_rows = df.shape[0]\n",
    "    logs.append(f\"{ticker_info} Initial rows: {initial_rows}\")\n",
    "\n",
    "    # Convert index to datetime format\n",
    "    try:\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "    except Exception as e:\n",
    "        raise ValueError(\"Index could not be converted to datetime format.\") from e\n",
    "\n",
    "    # Remove duplicate rows\n",
    "    df = df.sort_index()\n",
    "    df = df[~df.index.duplicated(keep='first')]\n",
    "    logs.append(f\"{ticker_info} Removed duplicate index entries.\")\n",
    "\n",
    "    # Remove missing values\n",
    "    before = df.shape[0]\n",
    "    df = df.dropna(subset=required_columns)\n",
    "    logs.append(f\"{ticker_info} Dropped {before - df.shape[0]} rows with NaNs.\")\n",
    "\n",
    "    # Remove nonsense entries\n",
    "    before = df.shape[0]\n",
    "    df = df[(df['Open'] > 0) & (df['High'] > 0) & (df['Low'] > 0) & (df['Close'] > 0) & (df['Volume'] >= 0)]\n",
    "    logs.append(f\"{ticker_info} Dropped {before - df.shape[0]} rows with invalid values.\")\n",
    "\n",
    "    # Final cleanup of NA's\n",
    "    df = df.ffill().bfill()\n",
    "    logs.append(f\"{ticker_info} Final rows: {df.shape[0]}\")\n",
    "\n",
    "    if verbose:\n",
    "        for line in logs:\n",
    "            print(line)\n",
    "\n",
    "    return df, logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52fb2fd2-19c8-49d9-a2b6-4f381eff2a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Clean multiple tickers\n",
    "def batch_clean_data(raw_data_dict):\n",
    "    \"\"\"\n",
    "    Applies the clean_data function to each DataFrame in a dictionary of raw data.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    raw_data_dict : dict\n",
    "        Dictionary where keys are ticker symbols and values are raw DataFrames.\n",
    "    verbose : bool, optional\n",
    "        Whether to print cleaning logs for each ticker. Default is True.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    tuple\n",
    "        (cleaned_data_dict, all_logs)\n",
    "        cleaned_data_dict : dict\n",
    "            Dictionary with cleaned DataFrames.\n",
    "        all_logs : dict\n",
    "            Dictionary mapping ticker symbols to their corresponding cleaning logs.\n",
    "    \"\"\"\n",
    "    cleaned_data = {}\n",
    "    logs = {}\n",
    "\n",
    "    for ticker, df in raw_data_dict.items():\n",
    "        cleaned_df, log = clean_data(df, ticker)\n",
    "        cleaned_data[ticker] = cleaned_df\n",
    "        logs[ticker] = log\n",
    "\n",
    "    return cleaned_data, logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb873541-e518-44fd-9177-0322d058ef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load data from CSV\n",
    "def load_data(file_path):\n",
    "    '''\n",
    "    Loads a CSV file as a DataFrame with a datetime index.\n",
    "\n",
    "    '''\n",
    "\n",
    "    df = pd.read.csv(file_path, index_col=0, parse_dates=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31c8cf19-d9a8-4ab5-ab7d-9dc9e788a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Save cleaned data\n",
    "def save_clean_data(df, ticker, save_path=\"data/clean\", log_path=None):\n",
    "    \"\"\"\n",
    "    Saves a cleaned DataFrame to a CSV file with a standardized filename.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The cleaned DataFrame to be saved.\n",
    "    ticker : str\n",
    "        The stock ticker symbol (used in the filename).\n",
    "    save_path : str, optional\n",
    "        Directory where the cleaned CSV will be saved. Default is 'data/clean'.\n",
    "    log_path : str or None, optional\n",
    "        If provided, a log entry will be written to this file upon successful save.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    file_name = f\"{ticker}_clean.csv\"\n",
    "    file_path = os.path.join(save_path, file_name)\n",
    "    \n",
    "    df.to_csv(file_path)\n",
    "    \n",
    "    print(f\"[Saved] Cleaned data saved to: {file_path}\")\n",
    "    \n",
    "    if log_path:\n",
    "        with open(log_path, 'a') as f:\n",
    "            f.write(f\"{pd.Timestamp.now()}: Saved cleaned data for {ticker} to {file_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4e562cf-c71c-4646-9f0e-7715fdc89178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Logging function\n",
    "def log_pipeline_step(log_path, message):\n",
    "    \"\"\"\n",
    "    Appends a timestamped message to a log file.\n",
    "\n",
    "    This function is useful for recording the steps of a data pipeline,\n",
    "    such as downloading, cleaning, or saving data, to help with debugging,\n",
    "    traceability, and auditing.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    log_path : str\n",
    "        The file path to the log file where the message will be saved.\n",
    "        If the file does not exist, it will be created.\n",
    "    message : str\n",
    "        The message to log. It will be prefixed with the current timestamp.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    with open(log_path, 'a') as f:\n",
    "        f.write(f\"{pd.Timestamp.now()}: {message}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81935c00-58ad-43cf-9d6a-bb3baa7f53a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (StatArb)",
   "language": "python",
   "name": "stat-arb-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
